# DHAIE Press Kit (Design Human AI Engineering and Enhancement)

[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC_BY_NC_SA_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)  
[![Website](https://img.shields.io/badge/Visit-Website-blue)](https://www.designhumanai.com)  
[![GitHub](https://img.shields.io/badge/GitHub-Repository-black)](https://github.com/designhumanai/design-human-ai)

**🌐 Language:** English | [Russian](README.md)

Welcome to the official press kit for the **DHAIE** project.  
This resource is designed for journalists, researchers, partners, and anyone interested in evaluating AI project claims for genuine engineering and scientific merit.

We document not marketing slogans, but working artifacts, plans, and criteria—elements that can be reproduced and verified.  
We embrace skepticism as a tool for improvement and respond to it with concrete actions.

---

## 🚀 About DHAIE

**DHAIE (Design Human AI Engineering and Enhancement)** is an engineering and research framework for designing human-centered AI systems.

**Our hypothesis**: The next qualitative breakthrough will be achieved not merely through parameter scaling, but through architectural and methodological solutions that capture and amplify individual human micro-strategies of thinking.

**Our approach**: Philosophy → operational principles → architecture → reproducible artifacts.

---

## 📂 Press Kit Structure

| File / Folder | Contents | Status |
| :--- | :--- | :--- |
| `press_releases/` | Official press releases | 🟡 In preparation |
| `fact_sheet.en.md` | Key facts: mission, theses, contacts | ✅ Available |
| `faq.en.md` | Technical and ethical Q&A | ✅ Available |
| `highlights.en.md` | Milestones and achievements | ✅ Available |
| `team_bios.en.md` | Team biographies with profiles and publications | ✅ Available |
| `media_assets/` | Logos, diagrams, examples | 🟡 Partially populated |
| `papers/` | Whitepaper, preprints, publications | ✅ ISBN edition available |
| `presentations/` | Slides, presentation materials | 🟡 In preparation |
| `in_the_news.en.md` | Project mentions | 🔄 As they appear |

---

## 🔑 DHAIE's Two-Level Principle System

DHAIE is built on complementary levels of abstraction:

### Philosophical Level
**Document**: [dhaie_philosophy.en.md](../docs/dhaie_philosophy.en.md) (version 1.2, September 29, 2025)

**Theoretical foundation:**
- Second-order cybernetics (Heinz von Foerster) — the observer as part of the system
- Enactivism (Varela, Thompson, Rosch) — cognition through interaction
- Assemblage theory (Deleuze & Guattari) — emergent nature of human-machine systems
- Phenomenology of technology (Heidegger, Verbeek) — technology as a mode of revealing being

### Engineering Level
**Document**: [engineering_guidelines.en.md](../docs/engineering_guidelines.en.md) (version 2.0)

**11 operational principles** with measurable criteria:
1. Synergetic Sustainability
2. Mutual Calibration
3. Cognitive Symbioticity
4. Ethical Gradient
5. Interpretable Transparency
6. Proactive Safety
7. Inclusive Design
8. Distributed Responsibility
9. Evolutionary Learnability
10. Confidential Personalization
11. Mutual Enrichment

**+ 4 meta-principles** of system integration:
- Recursive Improvement
- Integrative Wholeness
- Contextual Adaptation
- Spiral Coherence

**Connection between levels**: Philosophical foundations define the *why* and *what*, engineering principles define the *how* and *with what metrics*.

---

## 🔬 Scientific Novelty (Concise and Confident)

Contemporary LLMs and classical NLP methods rely on statistical approximations of language. They excel at text generation but **do not solve the problem of empirical emergent modeling of individual cognitive micro-strategies**.

### Key Difference of DHAIE:

**Cognitive micro-strategies** — formalization and measurement of *not "what" the user does, but "how" they think*:
- Patterns of attention organization (e.g.: problem → historical context → ironic reframing → solution)
- Sequences of cognitive operations (abstraction → concretization vs. concrete → generalization)
- Strategies for handling uncertainty (visual metaphors vs. statistical arguments)

**Architectural solutions**:
- **Cognitive Pattern Layer** — extraction and modeling of micro-strategies from interaction history
- **Reflexive Interface Layer** — adaptive transparency and metacognitive monitoring
- **Human-AI Coupling Layer** — formation of emergent properties through structural coupling

**This is not simply input-output transformation**, but a process where new cognitive patterns **emergently** arise and become system artifacts.

### Distinction from Existing Approaches:

| Aspect | Traditional AI | Explainable AI (XAI) | DHAIE |
|--------|-----------------|----------------------|-------|
| What is modeled | Content | Model decisions | **Participant's thought processes** |
| Personalization | Recommendations | Explanations | **Cognitive adaptation** |
| Transparency | Black box | Post-hoc explanations | **Reflexive architecture** |
| Goal | Automation | Trust | **Mutual enrichment** |

---

## 🧾 Status and Official Documents

### Completed Publications

**📘 Internal Electronic Edition** (October 2, 2025):
- **Title**: "DHAIE — Human-Centered Solutions"
- **Volume**: 21 pages
- **Publisher**: Viktor Savitskiy
- **Library classification**: BBK 16.32+88.811
- **ISBN**: 978-5-600-04236-0
- **Registration**: Russian Book Chamber
- **Status**: Conceptual foundation for academic publications

**Philosophical Foundation**: [dhaie_philosophy.en.md](../docs/dhaie_philosophy.en.md) v1.2 (September 29, 2025) — academic article with theoretical grounding.

### In Development

- **Q4 2025**: arXiv preprint (whitepaper v0.1) based on ISBN edition
- **Q4 2025**: Publication of core GitHub repository (core v0.1)
- **Q1 2026**: Benchmark results against Transformer/XAI baselines
- **Q1 2026**: Reproducibility kit (datasets, pipelines, metrics)

Architectural artifacts and private prototypes are available to partners under NDA.

---

## 🎯 Technical Snapshot (v0.1)

### Architecture v0.1 (Concept)

**Three-layer modular system:**

```
┌───────────────────────────────────────────────────────┐
│              DHAIE Architecture v0.1                  │
├───────────────────────────────────────────────────────┤
│  [Cognitive Pattern Layer]                            │
│  ┌─────────────────┐ ┌─────────────────┐ ┌──────────┐ │
│  │ Micro-Strategy  │ │   Attention     │ │ Temporal │ │
│  │  Extraction     │→│   Modeling      │→│ Persist. │ │
│  └─────────────────┘ └─────────────────┘ └──────────┘ │
├───────────────────────────────────────────────────────┤
│  [Reflexive Interface Layer]                          │
│  ┌─────────────────┐ ┌─────────────────┐ ┌──────────┐ │
│  │   Meta-Cog      │ │    Adaptive     │ │Assemblage│ │
│  │  Monitoring     │↔│  Transparency   │↔│Formation │ │
│  └─────────────────┘ └─────────────────┘ └──────────┘ │
├───────────────────────────────────────────────────────┤
│  [Human-AI Coupling Layer]                            │
│  ┌─────────────────┐ ┌─────────────────┐ ┌──────────┐ │
│  │  Structural     │ │   Emergent      │ │ Positive │ │
│  │   Coupling      │→│  Properties     │→│ Spirals  │ │
│  └─────────────────┘ └─────────────────┘ └──────────┘ │
└───────────────────────────────────────────────────────┘
```

### Metrics (Captured in Validation Studies)

**Micro-strategy modeling quality:**
- Pattern extraction accuracy: >85% (target metric)
- Fidelity of cognitive style reproduction
- Coverage of cognitive preference explanations

**Interaction effectiveness:**
- NASA-TLX (cognitive load)
- Task Augmentation Index (human performance with AI support)
- Explanation Satisfaction Score

**Robustness:**
- Robustness to distributional shift
- Temporal consistency of metrics
- Emergent properties detection rate

### Baselines and Datasets

**Comparison baselines:**
- Transformer-based models (GPT-4, Claude)
- XAI tools (LIME, SHAP, attention-based explainers)
- Traditional adaptive systems

**Datasets:**
- e-SNLI (natural language explanations)
- CoS-E (commonsense explanations)
- HumanEval-X (code and reasoning)
- Specialized cognitive tasks (in development)

**Artifacts**: Minimal working prototype in private repository; public core module release — Q4 2025.

---

## 📈 Roadmap

**Detailed roadmap**: [docs/roadmap.en.md](../docs/roadmap.en.md)

### Phase 1: Fundamental Research (6-12 months, current)
- ✅ Philosophical foundations documented (v1.2)
- ✅ Engineering principles published (v2.0)
- ✅ ISBN edition of conceptual foundation completed
- 🔄 Formalization of micro-strategy extraction methodology
- 🔄 Validation studies with control groups
- 🔄 Development of open-source cognitive pattern dataset
- 📅 Seeking 3-5 academic labs for independent validation

**Community Goal**: Develop and validate a method for identifying 5-7 basic micro-strategies with >85% accuracy on a control group of 100+ participants.

### Phase 2: Prototyping (12-18 months)
- **Q4 2025**: arXiv preprint (whitepaper v0.1)
- **Q4 2025**: Publication of core GitHub repository (core v0.1)
- **Q1 2026**: Benchmarks against Transformer/XAI baselines
- **Q1 2026**: Publication of reproducibility kit
- **Q2 2026**: MVP reflexive interface
- **Q2 2026**: Architectural experiments with transformer alternatives

**Community Goal**: Launch 10+ pilot projects with the open-source community. Reach 100+ active contributors.

### Phase 3: Scaling (18-36 months)
- **2026**: Integration with existing AI platforms
- **2026**: Industry applications (education, healthcare, R&D)
- **2027**: International collaboration and standardization

**Community Goal**: Create an ecosystem of 50+ organizations using DHAIE principles. Establish ethical standards for micro-cognitive technology applications.

---

## 📰 Latest News

- **10/02/2025** — Completed internal edition "DHAIE — Human-Centered Solutions" (ISBN 978-5-600-04236-0). First arXiv preprint is being prepared based on it.
- **09/29/2025** — Published philosophical foundation of the project (dhaie_philosophy.en.md v1.2)
- **10/01/2025** — Released Engineering Guidelines v2.0 with 11 operational principles and 4 meta-principles

Expect whitepaper and first press releases in `press_releases/` in Q4 2025.

---

## 👥 Team and Experience Verification

**Details**: [team_bios.en.md](team_bios.en.md)

**Current composition**: 3 core researchers + external collaborations and expert reviews.

Each biography includes:
- Links to Google Scholar, LinkedIn, GitHub
- Relevant publications
- Areas of expertise
- Verification status: "confirmed" / "in progress" / "in development"

**Transparency note**: We explicitly mark areas requiring external verification and do not hide development status.

---

## ❓ Addressing Common Skepticism

### "Where's the code?"
**Status**: Public release of core module scheduled for Q4 2025.  
**Reason for delay**: We're first validating the micro-strategy extraction methodology in academic labs to publish a reproducible system rather than a "proof of concept."

### "Why ISBN and not a peer-reviewed publication?"
**ISBN edition** — legal registration of intellectual property and conceptual foundation.  
**arXiv preprint** (Q4 2025) — scientific version for peer-review community.  
**These are different tools for different purposes**, not mutually exclusive.

### "What's genuinely new? Isn't this just personalization?"
**No.** Traditional personalization adapts **content** (what to show).  
DHAIE adapts **processes** (how to think together).

**Example**:
- **Netflix**: "You'll enjoy these movies" (content)
- **DHAIE**: "You prefer analyzing through historical analogies → let's structure new information exactly that way" (process)

### "Can we see the architecture?"
Conceptual architectural descriptions are available in this press kit and technical documentation.
Detailed architectural specifications are protected as intellectual property and available to partners under NDA during commercial negotiations.

### "Is this AGI?"
**No.** We do not aim to create autonomous AGI.  
DHAIE designs conditions for **mutual becoming** of human and AI, where each enhances the capabilities of the other. See [comparison table in philosophy](../docs/dhaie_philosophy.en.md#comparison-of-agi-approaches).

---

## ✅ How to Verify Our Claims

### Already Available for Verification:

- ✅ **[Philosophical foundations](../docs/dhaie_philosophy.en.md)** — complete theoretical basis with bibliography
- ✅ **[Engineering Guidelines](../docs/engineering_guidelines.en.md)** — 11 operational principles with criteria
- ✅ **[Roadmap](../docs/roadmap.en.md)** — measurable goals and timelines
- ✅ **ISBN edition** — registered with Russian Book Chamber (978-5-600-04236-0)

### Will Be Available:

- **Q4 2025**: arXiv preprint + reproducible pipelines
- **Q1 2026**: Benchmark results against state-of-the-art
- **Q1 2026**: Open-source dataset of anonymized cognitive patterns
- **Q2 2026**: Pilot implementations and case studies

**Verification methodology**:
1. Philosophical foundations → theoretical critique via GitHub Issues
2. Engineering principles → reproduction in your own projects
3. Metrics → independent validation in academic laboratories

---

## 📞 Contacts

### For Press and Collaborations:
- **Email**: press@designhumanai.com
- **Website**: https://designhumanai.com *(in development)*
- **GitHub**: https://github.com/designhumanai/design-human-ai

### Technical / Research Inquiries:
- **Email**: research@designhumanai.com
- **GitHub Issues**: For methodological discussions

### Commercial Licensing:
- **Email**: dhaie@designhumanai.com

### Community:
- **Telegram**: [@DHAIE_official](https://t.me/DHAIE_official)
- **GitHub Discussions**: [coming soon]

**Response time**: Within 48 hours for all inquiry categories.

> **Note**: Architectural specifications and private prototypes are provided to partners under NDA.

---

## 🎯 What You Can Do Now

### If you're a journalist:
1. ✉️ Request an interview with the founder (press@designhumanai.com)
2. 📄 Get exclusive access to whitepaper draft (NDA)
3. 📅 Reserve a spot at the v0.1 release press briefing (Q4 2025)

### If you're a researcher:
1. 📖 Study the [philosophical foundations](../docs/dhaie_philosophy.en.md)
2. 💬 Propose methodological critique via GitHub Issues
3. 🤝 Participate in Phase 1 validation studies

### If you're a potential partner:
1. 🔒 Request NDA for access to architectural specifications
2. 🧪 Discuss pilot implementation in your organization
3. 🗺️ Participate in shaping roadmap for your use cases

---

## ✅ Operational Checklist (Upcoming Releases)

- [ ] Publish ISBN edition abstract in `papers/README.md`
- [ ] Prepare and upload preprint to arXiv (whitepaper v0.1) — Q4 2025
- [ ] Publish minimal repository (core v0.1) with instructions — Q4 2025
- [ ] Publish first benchmark reports — Q1 2026
- [ ] Release reproducibility kit (datasets, metrics, pipelines) — Q1 2026

---

## 🔐 Licensing

[![GPL-3.0](https://img.shields.io/badge/Code-GPL--3.0-blue.svg)](../LICENSE.md)
[![CC BY-NC-SA 4.0](https://img.shields.io/badge/Docs-CC_BY_NC_SA_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)

**This document**: CC BY-NC-SA 4.0  
**Project code**: GPL-3.0-only  
**Commercial licensing**: dhaie@designhumanai.com

---

*This press kit reflects the current state of the project and our honest operational position: we don't sell promises—we document steps that allow the scientific and engineering community to verify our claims. Criticism, verification, and replication are part of our process.*

**Last updated**: October 9, 2025  
**Document version**: 2.0

---

**© 2024-2025 Viktor Savitskiy, DHAIE Project**  
*This document is distributed under CC BY-NC-SA 4.0 license*

<!--
SPDX-License-Identifier: CC-BY-NC-SA-4.0
Copyright © Viktor Savitskiy, 1995–2025
-->
