<!--
SPDX-License-Identifier: CC-BY-NC-SA-4.0
Copyright ¬© Viktor Savitskiy, 1995‚Äì2025
-->

# Design Human AI Engineering and Enhancement (DHAIE): Principles

> **Target audience**: A practical guide for developers, system designers, and researchers creating adaptive human-AI interfaces. This document translates DHAIE's philosophical foundations into actionable principles with measurable criteria.

> **‚ö†Ô∏è STATUS: DRAFT FOR COMMUNITY VALIDATION (v2.0)**
> 
> These principles are under active development and require empirical validation (see [roadmap.en.md](./roadmap.en.md)). We invite the community to provide critique, present case studies of contradictions, and suggest refinements to formulations.
>
> **Do not use as a ready-made standard** ‚Äî this is research work open to evolution.
>
> **üåê Language:** English | [–†—É—Å—Å–∫–∏–π](engineering_guidelines.md)

> **Part of the DHAIE Research Series**

---

## About This Document

**Preamble**: These principles operationalize the philosophical foundations outlined in [dhaie_philosophy.en.md](./dhaie_philosophy.en.md). They represent a normative framework for designing systems that implement concepts from second-order cybernetics, enactivism, and assemblage theory in the context of human-AI interaction.

**Why this matters in practice**: Traditional "human-centered design" assumes stability of user needs. DHAIE recognizes that humans and systems mutually transform through interaction. These principles help design systems that don't merely "satisfy needs" but create space for the evolution of capabilities on both sides.

---

## Brief Glossary

| Term | Definition |
|------|------------|
| **Participant** | A human actively constructing system capabilities (not a passive "user") |
| **Assemblage** | A dynamic, self-organizing system of human-AI interaction |
| **Micro-strategies** | Formalized patterns of individual attention, thinking and problem-solving, independent of content |
| **Mutual Calibration** | Process of building measurable interaction predictability (not "trust") |
| **Dynamic Sustainability** | Balance of changes without returning to a fixed state |
| **Reflexive Interface** | A system capable of observing and modifying its own processes |

*Complete glossary: see [dhaie_philosophy.en.md#glossary](./dhaie_philosophy.en.md#glossary)*

---

## Core Principles

### 1. Synergistic Sustainability
*Maintaining dynamic balance between humans, AI, and environment*

**Essence**: Creating systems that evolve with participants without sacrificing long-term sustainability for short-term gains.

**Implementation**:
- Integrating ecological, social, economic, and technological sustainability
- Supporting dynamic sustainability between evolving participant interaction patterns and AI computational capabilities
- Cyclical assessment of impact on all aspects of sustainable development
- Identifying and overcoming local development maxima

**Compliance Criteria**:
| Criterion | Minimum Threshold | Target Value |
|-----------|-------------------|--------------|
| Impact assessment cycle | Mandatory (ESG+Tech) | Quarterly review |
| Side effects documentation | All 4 domains | + quantitative metrics |
| Local maximum absence justification | Mandatory | + alternative paths |
| Synergistic Sustainability Index | ‚è≥ TBD (Phase 1) | ‚è≥ TBD (Phase 1) |

**Practical Example**: Before deploying a new personalization algorithm, simulate long-term effects on participants' cognitive diversity (avoiding "filter bubble" as a local maximum).

**Philosophical Foundation**: See section "Assemblages and Positive Spirals" in [dhaie_philosophy.en.md](./dhaie_philosophy.en.md)

---

### 2. Mutual Calibration
*Building interaction predictability without anthropomorphization*

**Essence**: Not "earning trust," but creating measurable predictability of both sides' actions in the assemblage.

**Implementation**:
- Designing mechanisms for gradual calibration of predictability between participant and AI
- Integrating feedback loops to adjust interpretive models on both sides
- Predicting situations that disrupt mutual predictability
- Adapting transparency level of processes depending on context

**Compliance Criteria**:
| Criterion | Minimum Threshold | Target Value |
|-----------|-------------------|--------------|
| Calibration Index | >0.60 for new contexts | >0.75 for routine operations |
| Recalibration protocol | Activates automatically | + predictive triggering |
| Decision reasoning explanation | Mandatory | + multi-level detail |
| Predictability measurability | Quantitative metric | + dynamics visualization |

**Practical Example**: When a participant ignores system suggestions three times, the interface automatically offers a calibration session: "My recommendations seem misaligned with your current approach. Review my reasoning?"

**Terminological Note**: The term "trust" is replaced with "mutual calibration" to avoid anthropomorphization and emphasize the technical nature of predictability.

---

### 3. Cognitive Symbioticity
*Enhancing participant capabilities through adaptation to thinking micro-strategies*

**Essence**: The system adapts to the participant's *way* of thinking, not just content preferences.

**Implementation**:
- Developing systems that enhance participants' cognitive abilities rather than replacing them
- Formalization of individual microstrategies (patterns of attention, thinking and problem-solving)
- Balanced distribution of cognitive load between participant and AI
- Supporting development of new cognitive skills during interaction

**Compliance Criteria**:
| Criterion | Minimum Threshold | Target Value |
|-----------|-------------------|--------------|
| Micro-strategy identification | 3-5 patterns in 10 interactions | Refinement in 5 interactions |
| Cognitive load reduction (NASA-TLX) | -15% from baseline | -20% from baseline |
| Participant metacognitive reflection | Mandatory survey | + spontaneous feedback |
| Micro-strategies map | ‚è≥ TBD (Phase 1) | Vector representation |

**Practical Example**: A researcher with the micro-strategy "problem ‚Üí historical context ‚Üí ironic reframing ‚Üí solution" receives analytics in this sequence, not the standard "introduction ‚Üí data ‚Üí conclusions."

**Philosophical Foundation**: See section "Micro-strategies and Cognitive Patterns" in [dhaie_philosophy.en.md](./dhaie_philosophy.en.md)

---

### 4. Ethical Gradient
*Adaptive ethics with conflict resolution mechanisms*

**Essence**: The system doesn't impose universal ethics but ensures transparent resolution of ethical conflicts.

**Implementation**:
- Implementing ethical principles accounting for cultural and individual differences
- Developing hierarchical ethical frameworks for conflict resolution
- Predictive ethical analysis of new functionalities before deployment
- Creating ethical calibration mechanisms when discovering new scenarios

**Compliance Criteria**:
| Criterion | Minimum Threshold | Target Value |
|-----------|-------------------|--------------|
| Ethical Map presence | Mandatory | + contextual priorities |
| Conflict resolution procedure | Mandatory | + human involvement in dilemmas |
| Decision documentation | 100% of ethical cases | + public audit trail |
| Appeals procedure | Mandatory | + external review board |

**Conflict Resolution Example**: A medical AI faces a contradiction: "patient confidentiality" vs "disclosure to relatives in critical situations." The system doesn't choose itself but presents the participant with a structured dilemma with arguments from both sides.

**Practice Connection**: See [ethics.en.md](./ethics.en.md) for detailed application protocols

---

### 5. Interpretable Transparency
*Multi-level explanations adapted to audience*

**Essence**: Transparency doesn't mean "show all the code." It's providing explanations at a level matching participant needs.

**Implementation**:
- Ensuring system comprehensibility for participants with different technical backgrounds
- Multi-level approach to explaining AI operation principles (from metaphors to mathematics)
- Adapting explanation detail depending on request
- Visualizing decision-making processes

**Compliance Criteria**:
| Criterion | Minimum Threshold | Target Value |
|-----------|-------------------|--------------|
| Explanation detail levels | Minimum 3 levels | 5+ levels |
| Explanation utility tracking | Mandatory | + participant adaptation |
| Decision traceability | From result to data | + intermediate steps |
| Explanation Satisfaction Score | >3.5/5.0 | >4.0/5.0 |

**Practical Example**: To the question "Why this recommendation?" the system can answer:
- Level 1: "You usually prefer X in such situations"
- Level 2: "Analysis of your last 15 decisions shows a pattern..."
- Level 3: "Bayesian model with weights [show data]..."

**Architectural Implementation**: Adaptive Transparency Layer in reflexive interface architecture

---

### 6. Proactive Safety
*Preventing risks through prediction*

**Essence**: Safety is built into design, not added post factum.

**Implementation**:
- Transitioning from reactive to proactive safety model
- Predicting potential risks through scenario modeling
- Integrating self-regulation and self-recovery mechanisms
- Creating rapid response protocols for unforeseen threats

**Compliance Criteria**:
| Criterion | Minimum Threshold | Target Value |
|-----------|-------------------|--------------|
| Worst-case scenario coverage | ‚â•10 scenarios | ‚â•25 scenarios |
| Automatic circuit breakers | Mandatory | + graduated triggering |
| Threat model explainability | Mandatory | + visualization |
| Security audits | Quarterly internal | + external experts |

**Practical Example**: A content generation system has a built-in detector: "This text may be perceived as manipulative by 73% of participants with profile X. Reconsider?"

---

### 7. Inclusive Design
*Accessibility for all without uniformization*

**Essence**: Adapting to diversity rather than reducing to an "average user."

**Implementation**:
- Developing systems accessible to all social and demographic groups
- Accounting for diversity of cultural, physical, and cognitive characteristics
- Designing with consideration for marginalized groups' needs
- Ensuring equal access to technology benefits

**Compliance Criteria**:
| Criterion | Minimum Threshold | Target Value |
|-----------|-------------------|--------------|
| Testing with diverse groups | ‚â•3 cultural-demographic groups | ‚â•5 groups |
| WCAG compliance | 2.1 Level AA | 2.2 Level AAA |
| Alternative modalities | Minimum 2 (e.g., voice+text) | 3+ modalities |
| Inclusive audit | Mandatory | + community representatives |

**Practical Example**: A voice interface doesn't just "support accents" but adapts to individual speech patterns, including speech characteristics of people with aphasia or stuttering.

---

### 8. Distributed Responsibility
*Clear responsibility zones with final human accountability*

**Essence**: Automation doesn't mean delegating moral and legal responsibility to machines.

**Implementation**:
- Clear definition of responsibility zones between developers, participants, and AI systems
- **Ultimate Responsibility Principle**: Legal and moral responsibility for system actions remains with the human operator or developer organization
- Creating audit and decision-tracking mechanisms
- Implementing a dynamic responsibility scale that changes through interaction

**Compliance Criteria**:
| Criterion | Minimum Threshold | Target Value |
|-----------|-------------------|--------------|
| Final responsibility definition | For each decision | + risk gradation |
| Critical decision audit trail | 100% coverage | + autonomy level indication |
| Escalation protocol | Mandatory | + automatic triggering |
| Participant notification | Explicit | + interactive |

**Practical Example**: An autonomous HR assistant can rank candidates, but the final hiring decision is logged as the human recruiter's decision, who bears responsibility. The system reminds: "This is a recommendation. Final responsibility for the decision is yours."

**Philosophical Foundation**: See section "Ethics of Co-becoming" in [dhaie_philosophy.en.md](./dhaie_philosophy.en.md)

---

### 9. Evolutionary Learnability
*Adaptation without losing stability*

**Essence**: The system evolves but doesn't "forget" critically important patterns.

**Implementation**:
- Creating systems capable of self-improvement considering participant feedback
- Ensuring balance between stability and adaptability through selective learning
- Implementing mechanisms to preserve useful properties when changing parameters
- Knowledge transfer between different system components

**Compliance Criteria**:
| Criterion | Minimum Threshold | Target Value |
|-----------|-------------------|--------------|
| Change explainability | Mandatory | + evolution visualization |
| Anchor pattern protection | Mandatory | + explicit permission to change |
| Failed adaptation rollback | Available to participant | + automatic by metrics |
| Stability-Adaptability Index | ‚è≥ TBD (Phase 1) | Balance 0.5/0.5 |

**Practical Example**: An educational system adapts explanation methods to the student but doesn't change fundamental course concepts. If adaptation reduces material comprehension below threshold, the system offers to return to previous configuration.

---

### 10. Confidential Personalization
*Privacy by Design with technical guarantees*

**Essence**: Personalization is possible without centralized data collection through federated learning and local processing.

**Implementation**:
- Implementing "Privacy by Design" approach at all development stages
- Localizing personal data and minimizing its transmission
- Creating systems that work effectively with anonymized data
- Implementing differential privacy methods and federated learning

**Compliance Criteria**:
| Criterion | Minimum Threshold | Target Value |
|-----------|-------------------|--------------|
| Regulatory compliance | GDPR, CCPA compliance | + local regulations |
| Local data processing | Where technically possible | On-device by default |
| Participant data control | Full (export/deletion) | + granular settings |
| Differential privacy | Œµ < 1.0 for aggregates | Œµ < 0.5 |
| Asymmetric transparency | Mandatory | + real-time monitoring |

**Practical Example**: A medical AI assistant learns from user health patterns through federated learning: the model updates locally on the device, only weight updates are sent to the cloud, not raw health data.

**Critical Requirement**: See asymmetric transparency principle in [ethics.en.md](./ethics.en.md)

---

### 11. Mutual Enrichment
*Bidirectional capability growth*

**Essence**: Not only does the human train the system, but the system also facilitates development of human cognitive abilities.

**Implementation**:
- Ensuring knowledge transfer mechanisms not only from participant to system but also back
- Creating mutual learning cycles
- Forming metrics to assess mutual enrichment quality
- Identifying and spreading best interaction practices
- Designing collaborative problem-solving mechanisms

**Compliance Criteria**:
| Criterion | Minimum Threshold | Target Value |
|-----------|-------------------|--------------|
| Participant new skill articulation | Mandatory survey | + spontaneous reflection |
| Emergent capabilities tracking | Mandatory | + quantitative metrics |
| Assemblage superiority documentation | Minimum 3 cases | + systematic collection |
| Mutual Enrichment Index | ‚è≥ TBD (Phase 1) | Growth of both sides |

**Practical Example**: A creative writing system doesn't just suggest text variants but analyzes the author's stylistic techniques and suggests exercises to develop weak points: "You rarely use metaphors. Try describing this scene through comparison with a natural phenomenon."

**Philosophical Foundation**: Concept of assemblage as mutual becoming process in [dhaie_philosophy.en.md](./dhaie_philosophy.en.md)

---

## Meta-Principles

> **About meta-principles**: These represent DHAIE's reflexive level ‚Äî principles for developing and evolving the principles themselves, embodying second-order cybernetics ideas. They serve as tools for managing and adapting core principles.

**Application in Practice**: When conflicts arise between core principles or when adapting them to new contexts, priority is given to solutions that most align with meta-principles (especially "Integrative Wholeness" and "Spiral Coherence").

---

### 1. Principle of Recursive Improvement
*Self-reflexive evolution of the principle system*

**Essence**: DHAIE principles are applied to the DHAIE development process itself.

**Implementation**:
- Applying DHAIE principles to their own development and implementation process
- Constant evaluation and correction of principles considering new knowledge and experience
- Creating mechanisms to identify and eliminate contradictions between practice and theory
- Ensuring evolution of the principles themselves in accordance with technology and society development

**Application Example in DHAIE**: This document v2.0 results from applying this meta-principle ‚Äî we discovered terminological inconsistency with dhaie_philosophy.md and corrected it, applying the "Integrative Wholeness" principle to the documentation itself.

**Compliance Criteria**:
| Criterion | Periodicity | Mechanism |
|-----------|-------------|-----------|
| Principle review with practitioners | Quarterly | GitHub Discussions |
| Public changelog | With each change | Version history |
| Contradiction collection from cases | Continuous | GitHub Issues |

---

### 2. Principle of Integrative Wholeness
*Systems thinking in conflict resolution*

**Essence**: Principles form a unified ecosystem, not a list of isolated requirements.

**Implementation**:
- Considering all principles as a unified system, not separate elements
- Identifying and resolving contradictions between principles
- Creating mechanisms to assess systemic influence of changes in one principle on others
- Ensuring consistency and synergy between all principles

**Application Example in DHAIE**: When conflict arises between "Proactive Safety" (minimize risks) and "Mutual Enrichment" (give participant freedom to experiment), the system seeks a third-order solution: "Sandbox with controlled risks," where safety is ensured by boundaries but the participant is free within them.

**Compliance Criteria**:
| Criterion | Requirement | Tool |
|-----------|-------------|------|
| Principle interaction matrix | Mandatory | `/docs/principle_matrix.md` |
| New principle verification | Compatibility with all | Impact analysis checklist |
| Impact analysis for changes | Mandatory | Automated dependency check |

---

### 3. Principle of Contextual Adaptation
*Flexible prioritization without losing essence*

**Essence**: Principles aren't applied mechanically ‚Äî their weight depends on context.

**Implementation**:
- Flexible application of principles depending on specific system usage context
- Developing mechanisms to determine principle priority in various situations
- Creating "Contextual Priority Maps" for different system types
- Ensuring context-dependent principle interpretation without losing their essence

**Contextual Map Example**:

| System Type | Top-3 Priority Principles |
|-------------|--------------------------|
| Medical AI | 1. Proactive Safety<br>2. Ethical Gradient<br>3. Distributed Responsibility |
| Educational AI | 1. Cognitive Symbioticity<br>2. Mutual Enrichment<br>3. Inclusive Design |
| Creative Assistant | 1. Mutual Enrichment<br>2. Cognitive Symbioticity<br>3. Mutual Calibration |

**Compliance Criteria**:
| Criterion | Requirement | Document |
|-----------|-------------|----------|
| Contextual map for project | Mandatory | `context_priority_map.md` |
| Prioritization justification | Documented | In project documentation |
| Map revision | On context change | Change log |

---

### 4. Principle of Spiral Coherence
*Coordinated development of all system components*

**Essence**: All system aspects must evolve synchronously, avoiding imbalances.

**Implementation**:
- Ensuring coherent development of all system components in a spiral
- Defining metrics for assessing development coherence
- Developing synchronization mechanisms for different aspects' development rates
- Creating tools to identify and eliminate development imbalances
- Ensuring progressive movement along an ascending development spiral

**Application Example in DHAIE**: If technical architecture (architecture.md) outpaces ethical protocols (ethics.md), there's risk of creating a powerful system without sufficient safety guarantees. The spiral coherence principle requires synchronization: don't implement functionality lacking corresponding ethical procedures.

**Compliance Criteria**:
| Criterion | Requirement | Tool |
|-----------|-------------|------|
| Roadmap with parallel development | Technical + ethical components | See [roadmap.md](./roadmap.md) |
| Coherence Dashboard | Development balance visualization | Quarterly review |
| Suspension mechanisms | On imbalance | Automated alerts |

**Philosophical Foundation**: See concept "Positive Spirals" in [dhaie_philosophy.en.md](./dhaie_philosophy.en.md)

---

## Applying the Principles

**General Approach**: Principles aren't a rigid checklist. They form an adaptive system where priorities are determined by context and contradictions are resolved through meta-principles.

---

### 1. Principle Hierarchy

In different contexts, certain principles have higher priority, but all principles must be considered in decision-making.

**Mechanism**: For each system type, create a "Contextual Priority Map" (see Meta-Principle 3) that documents:
- Top-3 critical principles for this domain
- Principles with relaxed requirements (with justification)
- Known conflicts between principles and resolution methods

**Example**: In a real-time medical diagnostic system, "Proactive Safety" may temporarily limit "Interpretable Transparency" (detailed explanations slow response), but this must be explicitly documented.

---

### 2. Monitoring and Assessment

Regular evaluation of DHAIE system compliance with specified principles and correction when necessary.

**Mechanism**: 
- **Quarterly Audits**: Checking each principle against its compliance criteria
- **Metrics Dashboard**: Visualizing key metrics (calibration, enrichment, sustainability indices)
- **Community Review**: Public discussion of audit results with stakeholders

**Connection to Criteria**: See "Compliance Criteria" section in each principle.

---

### 3. Flexibility and Evolution

Principles must evolve with technologies and society while remaining true to their essence.

**Mechanism**: Applying Meta-Principle 1 "Recursive Improvement":
- Document versioning with changelog
- Public RFC (Request for Comments) for significant changes
- Preserving philosophical foundation while adapting formulations

**Example**: The term "trust" was replaced with "mutual calibration" in v2.0, preserving the principle's essence while improving conceptual precision.

---

### 4. Integration with Existing Norms

DHAIE principles should complement, not contradict, existing ethical and legal norms.

**Mechanism**: 
- Explicit mapping of DHAIE principles to existing standards (GDPR, IEEE 7010, EU AI Act)
- Documenting cases where DHAIE exceeds regulations (as best practice)
- Participating in future standards development

**Example**: Principle 10 "Confidential Personalization" is fully compatible with GDPR and adds requirements for local data processing (on-device), exceeding minimum legal requirements.

---

### 5. Education and Communication

Spreading understanding of DHAIE principles among developers, participants, and society at large.

**Mechanism**:
- Documentation at multiple levels (philosophy ‚Üí principles ‚Üí architecture ‚Üí examples)
- Case studies of principle application from real projects
- Open workshops and tutorials for developers

**Resources**: 
- Theory: [dhaie_philosophy.en.md](./dhaie_philosophy.en.md)
- Ethics: [ethics.en.md](./ethics.en.md)
- Practice: [Neurostiv Framework](https://github.com/designhumanai/neurostiv-framework)

---

### 6. Preventive Approach

Using principles not only to assess existing systems but to predict and prevent potential problems.

**Mechanism**:
- **Pre-design Analysis**: Before starting development, simulate principle compliance
- **Red Team Reviews**: Independent group seeks ways to violate principles in design
- **Scenario Planning**: Modeling worst-case scenarios for each principle

**Example**: Before implementing a new interface:
1. Simulate participant cognitive load (Principle 3)
2. Ethical analysis of possible dilemmas (Principle 4)
3. Privacy risk assessment (Principle 10)
4. Inclusivity check (Principle 7)

---

### 7. Collaborative Development

Engaging a broad range of stakeholders in developing and improving DHAIE principles.

**Mechanism ‚Äî DHAIE Governance Model**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     DHAIE Governance Board (12 seats)   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ 3 developer representatives           ‚îÇ
‚îÇ ‚Ä¢ 3 ethics expert representatives       ‚îÇ
‚îÇ ‚Ä¢ 3 participant/community representatives‚îÇ
‚îÇ ‚Ä¢ 3 researcher representatives          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Rotation: 50% seats every 12 months     ‚îÇ
‚îÇ Decisions: consensus or 75% votes       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Change Process**:
1. Anyone can propose changes via GitHub Issue
2. Community discussion (14 days minimum)
3. Formalization in RFC (Request for Comments)
4. Governance Board vote
5. Integration into document with version update

**Current Status**: Governance model is under formation (see [roadmap.en.md](./roadmap.en.md)).

---

## Criteria and Metrics: How to Measure Principle Compliance

**Section Status**: UNDER DEVELOPMENT ‚Äî Requires empirical validation in Phase 1

This section provides a framework for assessing system compliance with DHAIE principles. Metrics are under active development and will be refined based on pilot projects.

### Measurement Approach

**Three Metric Levels**:

1. **Binary Compliance** (‚úì/‚úó): Minimum requirements for claiming principle compliance
2. **Quantitative Metrics** (0-100): Measurable implementation quality indicators
3. **Qualitative Assessment**: Expert evaluation and community feedback

### Metric Summary Table by Principle

| Principle | Key Metric | Baseline | Target Value |
|-----------|-------------|----------|--------------|
| 1. Synergistic Sustainability | Synergistic Sustainability Index | TBD | TBD |
| 2. Mutual Calibration | Calibration Index | >0.60 | >0.75 |
| 3. Cognitive Symbioticity | NASA-TLX Reduction | Baseline | -20% |
| 4. Ethical Gradient | Ethical Map presence | Mandatory | + appeals procedure |
| 5. Interpretable Transparency | Explanation Satisfaction Score | >3.5/5 | >4.0/5 |
| 6. Proactive Safety | Worst-case scenario coverage | ‚â•10 | ‚â•25 |
| 7. Inclusive Design | Testing with diverse groups | ‚â•3 groups | ‚â•5 groups |
| 8. Distributed Responsibility | Audit trail completeness | 100% critical decisions | + autonomy levels |
| 9. Evolutionary Learnability | Stability-Adaptability Index | TBD | Balance 0.5/0.5 |
| 10. Confidential Personalization | Privacy by Design compliance | GDPR compliance | + Œµ<1.0 for DP |
| 11. Mutual Enrichment | Mutual Enrichment Index | TBD | Growth of both sides |

**TBD**: To Be Determined ‚Äî metric will be developed in Phase 1 (see [roadmap.en.md](./roadmap.en.md)) based on empirical data.

### Compliance Audit Process

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   DHAIE Compliance Audit Process        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Self-Assessment (project team)       ‚îÇ
‚îÇ    ‚îî‚îÄ Binary compliance checklist       ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 2. Metrics Collection (automated)       ‚îÇ
‚îÇ    ‚îî‚îÄ Quantitative metrics gathering    ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 3. Expert Review (external audit)       ‚îÇ
‚îÇ    ‚îî‚îÄ Qualitative assessment            ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 4. Community Feedback (public)          ‚îÇ
‚îÇ    ‚îî‚îÄ System participant survey         ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 5. Compliance Report (open)             ‚îÇ
‚îÇ    ‚îî‚îÄ Results publication + improvement ‚îÇ
‚îÇ        roadmap                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Frequency**: Quarterly for production systems, monthly for systems in active development.

**Publication**: All Compliance Reports are published openly, including identified non-compliances and remediation plans.

---

## Terminological Conventions

**Why This Section**: DHAIE terminology differs from traditional HCI/UX design because it stems from a different philosophical foundation. These differences aren't accidental ‚Äî they reflect a fundamental shift in understanding human-technology relationships.

| DHAIE Term | Instead of Traditional | Why the Distinction Matters |
|------------|------------------------|---------------------------|
| **Participant** | "User" | Emphasizes active role in co-constructing system capabilities, not passive consumption of functions |
| **Assemblage** | "Human-computer system" | Dynamic, self-organizing configuration from human-AI interaction. From Deleuze and Guattari's philosophy |
| **Micro-strategies** | "Cognitive style" | Formalized patterns of thought organization, independent of content. Algorithmically extractable |
| **Mutual Calibration** | "Trust" | Process of building measurable interaction predictability. Avoids anthropomorphization |
| **Dynamic Sustainability** | "Equilibrium" | Balance of changes without returning to fixed state. Processual rather than homeostatic metaphor |
| **Reflexive Interface** | "Adaptive interface" | System capable of observing and modifying its own decision-making processes (second-order cybernetics) |

**Usage Examples in Context**:

> ‚ùå "The user trusts the system when it's in equilibrium"
> 
> ‚úÖ "The participant and system achieve mutual calibration while maintaining the dynamic sustainability of the assemblage"

*Complete philosophical glossary: see [dhaie_philosophy.en.md#glossary](./dhaie_philosophy.en.md#glossary)*

---

## Connections to Other Project Documents

**Navigating the DHAIE Ecosystem**:

### For Theoretical Understanding
- üìò **[Philosophical Foundations](./dhaie_philosophy.en.md)** ‚Äî Academic article with justification through second-order cybernetics, enactivism, and assemblage theory
  - *Last update*: v1.2, September 29, 2025
  - *Target audience*: Researchers, philosophers, theorists
  - *Key concepts*: Micro-strategies, assemblages, reflexive interfaces

### For Ethical Practice
- üìó **[Ethical Protocols](./ethics.en.md)** ‚Äî Specific procedures for applying principles in sensitive contexts
  - *Last update*: v1.0, 2024
  - *Target audience*: Developers, designers, ethics committees
  - *Key topics*: Asymmetric transparency, educational/therapeutic applications

### For Technical Implementation
- üìô **[System Architecture](./architecture.en.md)** ‚Äî Technical specification of DHAIE components *(in development)*
  - *Expected*: Q1 2026
  - *Target audience*: Engineers, system architects
  - *Content*: Micro-Strategy Extraction Engine, Reflexive Interface specs, API

### For Practical Application
- üíª **[Neurostiv Framework](https://github.com/designhumanai/neurostiv-framework)** ‚Äî Working implementation of principles for adaptive teams
  - *Status*: Active development
  - *Target audience*: Developers, practitioners
  - *Contents*: Code, examples, integration instructions

### For Planning and Development
- üìã **[Roadmap](./roadmap.en.md)** ‚Äî Project development plan from theory to practice
  - *Status*: Living document
  - *Target audience*: All stakeholders
  - *Content*: Phases, metrics, community goals

### For General Introduction
- üìÑ **[README](../README.md)** ‚Äî Project entry point with audience navigation

---

## Contribution and Feedback

**How to Help the Project Evolve**:

### Report a Contradiction
Found a conflict between principles in your case?
1. Open an Issue in [GitHub Repository](https://github.com/designhumanai/design-human-ai)
2. Use "Principle Conflict Report" template
3. Describe context and conflict consequences

### Propose an Improvement
Have an idea how to formulate a principle more precisely?
1. Create a Pull Request with changes
2. In description justify through philosophical foundations
3. Indicate which meta-principles support your change

### Share a Case Study
Applying principles in practice?
1. Write a case in Markdown format
2. Submit to `/examples/case-studies/`
3. Include: context, applied principles, metrics, lessons learned

### Join the Governance Board
Want to participate in managing principle evolution?
- Follow announcements in repository Issues about Governance Board formation
- Participation criterion: active project contribution (code, research, cases)

### Communication Channels
- **GitHub Issues**: Technical questions, bug reports, suggestions
- **Discussions**: Philosophical discussions, principle interpretations
- **Community Forum**: [coming soon] For sharing application experience

---

<!-- UNIFIED CONTACTS BLOCK START -->
## üìû Contacts

**General inquiries:**
- üåê Website: [designhumanai.com](https://designhumanai.com)
- üìß Email: `info@designhumanai.com`
- üí¨ GitHub: [github.com/designhumanai/design-human-ai](https://github.com/designhumanai/design-human-ai)

**Commercial licensing:**
- üìß Email: `dhaie@designhumanai.com`

**Community:**
- üí¨ GitHub Discussions: [coming soon](https://github.com/designhumanai/design-human-ai/discussions)
- üí¨ GitHub Issues: [create issue](https://github.com/designhumanai/design-human-ai/issues/new/choose)
- üì± Telegram: [@DHAIE_official](https://t.me/DHAIE_official)

<!-- UNIFIED CONTACTS BLOCK END -->


## Version History and Changes

### v2.0 (current) ‚Äî October 2025
**Major revision after critical analysis**

Changes:
- ‚úÖ Aligned terminology with dhaie_philosophy.md
- ‚úÖ "Trust" ‚Üí "Mutual Calibration" (principle 2)
- ‚úÖ "Equilibrium" ‚Üí "Dynamic Sustainability" (principle 1)
- ‚úÖ "User" ‚Üí "Participant" (throughout)
- ‚úÖ Added specific compliance criteria for each principle
- ‚úÖ Unified criteria formatting (tables with Minimum/Target thresholds)
- ‚úÖ Added practical examples for each principle
- ‚úÖ Strengthened "Applying the Principles" section with mechanisms
- ‚úÖ Added contextual priority maps
- ‚úÖ Clarified principles 4 (conflict resolution) and 8 (final responsibility)
- ‚úÖ Added "Privacy by Design" principle to principle 10
- ‚úÖ Created "Criteria and Metrics" section
- ‚úÖ Added metric summary table
- ‚úÖ Improved readability through formatting
- ‚úÖ Removed all duplicates and editing artifacts
- ‚úÖ Roadmap extracted to separate roadmap.md file

Rationale: Eliminating contradictions with philosophical foundations and adding measurability for practical application.

### v1.0 ‚Äî 2024
**First public version**
- Basic structure of 11 principles + 4 meta-principles
- Original formulation from internal DHAIE engineering guide

---

## License and Usage

**License**: CC BY-NC-SA 4.0 (Creative Commons Attribution-NonCommercial-ShareAlike 4.0)

**Terms of Use**:
- ‚úÖ Permitted: non-commercial use in projects
- ‚úÖ Permitted: modification and creation of derivative works
- ‚úÖ Required: attribution to original author
- ‚úÖ Required: same license sharing for derivative works
- ‚ùå Restricted: commercial use requires explicit permission

**For commercial use**: Contact the author for a separate license.

**Citation**:
```
Savitskiy, V. (2025). Principles of Design Human AI Engineering 
and Enhancement (DHAIE) v2.0. GitHub. 
https://github.com/designhumanai/design-human-ai
```

---

## Acknowledgments

This document is the result of collective thinking and critical feedback from:
- Participants in early pilot projects
- Reviewers of philosophical foundations
- Open-source developer community
- Critics who pointed out contradictions in v1.0

Special thanks for the critical analysis that led to creation of v2.0.

---

**¬© 2024-2025 Viktor Savitskiy, DHAIE Project**  
*Version 2.0 ‚Äî Final revision after critical analysis and alignment with philosophical foundations*  

---

<!-- UNIFIED LICENSE BLOCK START -->
## üìú License

[![GPL-3.0](https://img.shields.io/badge/Code-GPL--3.0-blue.svg?style=for-the-badge)](LICENSES/SOFTWARE-GPL-3.0.md)
[![CC BY-NC-SA 4.0](https://img.shields.io/badge/Docs-CC_BY_NC_SA_4.0-lightgrey.svg?style=for-the-badge)](https://creativecommons.org/licenses/by-nc-sa/4.0/)

This work is distributed under two types of licenses, depending on content:

| Category | License | Scope |
|----------|---------|-------|
| Source code | GNU General Public License v3.0 | SOFTWARE / FRAMEWORK |
| Documentation, texts, visual materials | Creative Commons BY-NC-SA 4.0 | DOCS / RESEARCH / VISUALS |

**Terms of Use:**  
- ‚úÖ Permitted: non-commercial use and modification  
- ‚úÖ Required: attribution as *¬© Viktor Savitskiy (–°–∞–≤–∏—Ü–∫–∏–π –í–∏–∫—Ç–æ—Ä –ù–∏–∫–æ–ª–∞–µ–≤–∏—á), 1995‚Äì2025*  
- ‚úÖ Required: same license sharing for derivative materials  
- ‚ùå Restricted: commercial use requires separate licensing agreement

**Commercial licensing contact:** `dhaie@designhumanai.com`

**Copyright ¬© Viktor Savitskiy, 1995‚Äì2025**  
**DHAIE Project ‚Äî Design Human AI Engineering & Enhancement**  
All rights reserved under applicable international law.

<!-- UNIFIED LICENSE BLOCK END -->



## Final Reminder to the Reader

> These principles are not dogma but a research tool. They will evolve based on your application experience.
>
> If you discover that a principle works differently than described, or contradicts another principle in your context ‚Äî this is not an error in your application. This is a signal that the document needs refinement.
>
> Your practice shapes theory. Share your experience through GitHub Issues.

**Next Steps**:
1. Study the philosophical foundations: [dhaie_philosophy.en.md](./dhaie_philosophy.en.md)
2. Review ethical protocols: [ethics.en.md](./ethics.en.md)
3. Check the development plan: [roadmap.en.md](./roadmap.en.md)
4. See a working example: [Neurostiv Framework](https://github.com/designhumanai/neurostiv-framework)
5. Try applying principles in your project
6. Share results with the community

*Document last updated: October 2025*  
*Next scheduled revision: After Phase 1 completion (see roadmap.en.md)*
